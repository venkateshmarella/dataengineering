# Project: Venkatesh's Coding Playground ğŸš€

## Directory structure:
```
â”œâ”€â”€ resources
â”‚   â”œâ”€â”€ transform_sales_data.py
â”‚   â”œâ”€â”€ normalize_customer_info.py
â”œâ”€â”€ src/main/
â”‚   â”œâ”€â”€ pyspark/*spark with python based programs*
â”‚   â”œâ”€â”€ python/*pure python programs*
â”‚   â”œâ”€â”€ utils/*general utilities*
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ spark_session.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚â”€â”€ test/
|   |â”€â”€ pyspark/*test cases based in pyspark*
|   |â”€â”€ python/*test cases based in python language*
â”œâ”€â”€ requirements.txt
|â”€â”€ __init__.py
|â”€â”€  .gitignore
â”œâ”€â”€ README.md
```

This repository contains Python scripts and PySpark jobs for various data engineering tasks, including ETL transformations, file processing, and automation. Each job comes with test cases using `pytest`.

## ğŸ“ Structure
- `python/ pyspark/`: Core data transformation scripts
- `tests/`: Pytest-based test cases
- `utils/`: Reusable utility functions (e.g., Spark session, file helpers)

## ğŸ› ï¸ Setup
```bash
pip install -r requirements.txt
```

# Happy coding! âœ¨